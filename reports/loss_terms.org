#+BIND: org-export-use-babel nil
#+TITLE: loss_terms
#+AUTHOR: Paul Lodder, Pim Meerdink, Siem Teusink
#+EMAIL: <paul_lodder@live.nl>
#+DATE: January 5, 2021
#+LATEX: \setlength\parindent{0pt}
#+LaTeX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage[margin=0.8in]{geometry}
#+LATEX_HEADER_EXTRA:  \usepackage{mdframed}
#+LATEX_HEADER_EXTRA: \usepackage{tikz}
#+LATEX_HEADER_EXTRA: \usepackage{bm}
#+LATEX_HEADER_EXTRA: \usetikzlibrary{shapes,backgrounds}
#+LATEX_HEADER_EXTRA: \usepackage{verbatim}
#+LATEX_HEADER_EXTRA: \BeforeBeginEnvironment{minted}{\begin{mdframed}}
#+LATEX_HEADER_EXTRA: \AfterEndEnvironment{minted}{\end{mdframed}}
#+MACRO: NEWLINE @@latex:\\@@ @@html:<br>@@
#+PROPERTY: header-args :exports both :session loss_terms :cache :results value
#+OPTIONS: ^:nil
#+LATEX_COMPILER: pdflatex
* Introduction
This file serves the purpose of documenting our initial current understanding
of the loss terms presented in [[https://arxiv.org/pdf/2003.05707.pdf][our paper]]. We provide names for each of the loss
terms in *bold* as well, and introduce names for loss terms that have not been
explicitly named yet.
* Agents
Prior to introducing the loss terms, let us give a brief overview of the
structure of the framework and its agents. In essence we map all input to two
latent distributions which are meant to encode different aspects of the initial
features. In particular we aim to explicitly encode the sensitive information
separately from the target information, where the latter is used for downstream
tasks like prediction.\\
We have a *target encoder* and a *target discriminator*, parameterized
$\theta_{T}$ and $\phi_{T}$ respectively. The target encoder
maps our features to the target latent representation, which the discriminator
learns to map back to the corresponding label.  In addition, we have a
*sensitive encoder* and a *sensitive discriminator*, parameterized
$\theta_{s}$ and $\phi_{s}$ respectively. the sensitive encoder maps
input samples to latent samples such that the sensitive discriminator is able
to reconstruct the sensitive information from the latent representation.\\
The target encoder and sensitive encoder are parameterized by $\theta_{T}$ and
$\theta_{S}$, respectively. They share some parameters, $\theta = \theta_{T}
\cap \theta_{S}$. We define $\theta_{S}^{*} = \theta \setminus \theta_{T}$ and
$\theta_{T}^{*} = \theta \setminus \theta_{S}$

* Losses
The overall objective is defined as:
$$\underset{\theta_{T},\theta_{S},\phi{T},\phi{S}}{argmin}
\mathcal{L}_{T}(\theta_{T},\phi_{T}) +
\mathcal{L}_{S}(\theta_{S^{*}},\phi_{S}) \lambda_{E}\mathcal{L}_{E}(\theta_{T},
\phi_{S})  + \lambda_{OD}\mathcal{L}_{OD}(\phi_{T},\phi_{S})$$

| *Name*            | *Notation*                                 |
|-------------------+--------------------------------------------|
| /                 | <                                          |
| Target loss       | $\mathcal{L}_{T}(\theta_{T},\phi_{T})$     |
| Sensitive loss    | $\mathcal{L}_{S}(\theta_{S^{*}},\phi_{S})$ |
| Entropy loss      | $\mathcal{L}_{E}(\theta_{T}, \phi_{S})$    |
| OD loss           | $\mathcal{L}_{OD}(\theta_{T},\theta_{S})$  |
| Target OD loss    | $\mathcal{L}_{z_{T}}(\theta_{T})$          |
| Sensitive OD loss | $\mathcal{L}_{z_{S}}(\theta_{T})$            |

** *Representation losses*
We define two representation losses, a target loss and a sensitive loss, to
ensure that our encoder/decoder network is able to predict the true
distribution as best as we can.
*** *Target Loss*
$$\mathcal{L}_{T}(\theta_{T},\phi_{T}) = KL(p(y|x)\parallel q_{\phi_{t}}(y|z_{T}))$$
Important to note here is that this loss depends on the both target encoder
(generates target latent representation $z_{T}$ based on $x$) and discriminator
(responsible for $q_{\phi_{T}}(y|z_{T})$.\\
Intuitively, the target loss captures the extent to which the target discriminator,
parameterized by $\phi_{T}$ is able to correct mimic the true posterior
$p(y|x)$ based on the observed target latent variable $z_{T}$ as generated by
the target encoder.
*** *Sensitive loss*
$$\mathcal{L}_{S}(\theta_{S}^{*},\phi_{S}) = KL(p(S|x)\parallel
q_{\phi_{S}}(y|z_{S}))$$\\
Highly analogous to the target loss, except it uses the sensitive
attributes. It depends on both the sensitive encoder (generates the sensitive
latent representation $z_{S}$ based on $x$) and the sensitive discriminator
(responsible for $z_{\phi_{S}}(y|z_{S})$).\\
Note that there is a small asymmetry with respect to the target loss, in that
this loss is only used to compute gradients with respect to $\theta^{*}_{S}$,
i.e. only those parameters that the sensitive encoder uses but that are not
used by the target encoder. We think this is done to prevent this intersection
of the parameters (i.e. $\theta$) to be updated twice as much.\\
The sensitive loss captures the extent to which our sensitive discriminator,
parameterized by $\phi_{S}$ is able to correct mimic the true posterior based
$p(s|x)$ on the observed target latent variable $z_{S}$ as generated by the
target encoder.
*** *Loss derivation*
The representation target loss can be computed as follows:
#+BEGIN_EXPORT latex
\begin{equation}
  \begin{aligned}
    \mathcal{L}_{T}(\theta_{T},\phi_{T})
    &= KL(p(\bm{y}|\bm{x})\parallel q_{\phi_{T}}(\bm{y}|\bm{z}_{T})) \\
    &= - \sum_{\bm{y}} p(\bm{y} | \bm{x}) \log q_{\phi_T} (\bm{s} | \bm{z}_T)
    + \sum_{\bm{y}} p(\bm{y} | \bm{x}) \log p(\bm{y} | \bm{x})
  \end{aligned}
\end{equation}
#+END_EXPORT
The second part of this expression solely depends on the true posterior of our
data and hence does not depend on our neural network. Therefore, we drop it
here. What remains is equal to the cross-entropy loss:
#+BEGIN_EXPORT latex
\begin{equation}
  \label{eq:rep_target_loss}
\mathcal{L}_{T}(\theta_{T},\phi_{T}) = \sum_{\bm{y}} p(\bm{y} | \bm{x}) \log q_{\phi_T} (\bm{s} | \bm{z}_T)
\end{equation}
#+END_EXPORT
Again, this is the same as the cross-entropy loss over the output of the
discriminator. The representation sensitive loss can be computed similarly.
** *Entropy loss*
$$\mathcal{L}_{E}(\phi_{S},\theta_{T}) = KL(p(s|z_{T})\parallel\mathcal{U}(s))$$ This
is the entropy loss as it maximizes the entropy of the distribution over
sensitive classes $s$ given the target latent representation $z_{T}$. This term
maximizes the entropy as it forces the distribution $p(s|z_{T})$ to be as close
to the uniform distribution as possible. In essence this promotes fairness by
ensuring an equal distribution over sensitive classes for any given target
latent representation.
** *Orthogonal-disentangled losses*
$$\mathcal{L}_{OD}(\phi_{T},\phi_{S}) = \mathcal{L}_{z_{T}}(\theta_{T}) +
\mathcal{L}_{z_{S}}(\theta_{T})$$This term is called the orthogonal
disentangled loss (or OD loss) as it enforces disentanglement
(i.e. independence among dimensions) and orthogonality of the approximated
target $q_{\phi_{T}}(z_{T}|x)$ vs. sensitive $q_{\phi_{T}}(z_{S}|x)$ latent
distributions. Both of these conditions are enforced through the choice of the
priors.  The OD loss decomposes into the OD target and OD sensitive loss:
- $\mathcal{L}_{z_{T}}(\theta_{T}) = KL(q_{\theta_{T}}(z_{T} \vert x) \parallel
  p(z_{T}))$
- $\mathcal{L}_{z_{S}}(\theta_{S}) = KL(q_{\theta_{S}}(z_{S} \vert x) \parallel
  p(z_{S}))$
These terms enforce disentanglement by ensuring that the priors $p(z_{T})$ and
$p(z_{S})$ are decorrelated, i.e. $p(z_{T}) = \prod_{i=1}^{N_{T}}p(z_{T}^{i})$
and $p(z_{S}) = \prod_{i=1}^{N_{S}}p(z_{S}^{i})$. In particular, we can choose
a multivariate Gaussian with identity covariance, where $p(z_{T})$ and
$p(z_{S})$ are parameterized by $(\mu_{S}, \sigma_{S})$ and $(\mu_{M},
\sigma_{M})$, respectively.\\
Furthermore, the orthogonality constraint is enforced by choosing $\mu_{S}$
 and $\mu_{T}$ such that $\mu_{S} \perp \mu_{T}$

*** *Loss derivation*
We can write out the OD target loss as follows,
#+BEGIN_EXPORT latex
\[
\begin{aligned}
  \mathcal{L}_{\bm{z}_{T}}(\theta_{T})
  &= KL(q_{\theta_{T}}(\bm{z}_{T} \vert \bm{x}) \parallel p(\bm{z}_{T})) \\
  &= \sum_{i=1}^{d_T} KL(q_{\theta_{T}}z_{T}^i \vert \bm{x}) \parallel p(z_{T}^i))


\end{aligned}
\]
#+END_EXPORT
because both the prior and the encoder posterior are independent Gaussian distributions, the
KL divergence between the two is simply a sum over KL divergences between the
univariate Gaussians $q_{\theta_{T}}(z_{T}^i \vert \bm{x})$ and $p(z_{T}^i)$.

One KL divergence terms can be computed as follows:
#+BEGIN_EXPORT latex
\begin{equation}
  \begin{aligned}
    KL(q_{\theta_{T}}(z^i_T \vert \bm{x}) \parallel p(z^i_T))
    &= - \int q_{\theta_{T}}(z^i_T \vert \bm{x}) \log \frac{q_{\theta_{T}}(z^i_T \vert \bm{x})}
    {p(z^i_T)} d\bm{x} \\
    &= \frac{1}{2} \log (2 \pi \sigma_{p_T}^i)
    + \frac{(\sigma_{q_T}^i)^2(\mu_{q_T}^i - \mu_{p_T}^i)^2}{2 \sigma_{p_T}^i}
    - \frac{1}{2} (1 + \log 2\pi (\sigma_{q_T}^i)^2) \\
    &= \log \frac{\sigma_{p_T}^i}{\sigma_{q_T}^i}
    + \frac{(\sigma_{q_T}^i)^2(\mu_{q_T}^i - \mu_{p_T}^i)^2}{2 \sigma_{p_T}^i}
    - \frac{1}{2}
  \end{aligned}
\end{equation}
#+END_EXPORT
In practice, we will compute the element-wise KL divergence between the prior
and posterior and sum over the result. The OD losses therefore require the
output /means/ and /variances/ of the encoder network and the /prior distributions/
of the latent variable.
The OD sensitive loss can be computed in a similar way.
